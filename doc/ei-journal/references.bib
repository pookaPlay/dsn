1.	Long, J., E. Shelhamer, and T. Darrell. Fully Convolutional Networks for Semantic Segmentation. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015.
2.	Sutton, C. and  McCallum, A, An Introduction to Conditional Random Fields for Relational Learning, in Introduction to Statistical Relational Learning, L. Getoor and B. Taskar, Editors. 2007.
3.	Chen, L.-C., et al., Semantic image segmentation with deep convolutional nets and fully connected crfs. arXiv preprint arXiv:1412.7062, 2014.
4.	Zheng, S., et al., Conditional random fields as recurrent neural networks. arXiv preprint arXiv:1502.03240, 2015.
5.	Arbelaez, P., et al., Contour Detection and Hierarchical Image Segmentation. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 2011. 33(5): p. 898-916.
6.	Dollár, P. and C.L. Zitnick. Structured forests for fast edge detection. in Computer Vision (ICCV), 2013 IEEE International Conference on. 2013. IEEE.

Corso, J.J., A. Yuille, and Z. Tu. Graph-Shifts: Natural Image Labeling by Dynamic Hierarchical Computing. in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition. 2008.

Mangan, A.P. and R.T. Whitaker, Partitioning 3D surface meshes using watershed segmentation. IEEE Transactions on Visualization and Computer Graphics, 1999. 5(4): p. 308-321.
	
@INPROCEEDINGS{Long2015,
  author={J. {Long} and E. {Shelhamer} and T. {Darrell}},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Fully convolutional networks for semantic segmentation}, 
  year={2015},
  volume={},
  number={},
  pages={3431-3440},}
  %[2]
  @INBOOK{Getoor2007,
  booktitle={Introduction to Statistical Relational Learning}, 
  title={An Introduction to Conditional Random Fields for Relational Learning}, 
  editor={L. {Getoor} and B. {Taskar}},
  year={2007},
  volume={},
  number={},
  pages={93-127},}
  
@article{Sutton2011,
author={Sutton, Charles and McCallum, Andrew},
title={An Introduction to Conditional Random Fields},
journal={Foundations and Trends in Machine Learning},
volume={4},
number={4},
year={2011},
pages={267-373},
}
%[3]
@misc{Chen2014,
author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
title={Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs},
howpublished = {arXiv 1412.7062 [cs.CV]},
year=2014,
 }

@misc{Wolf2019,
author={Wolf, Steffen and  Bailoni, Alberto and  Pape,  Constantin and  Rahaman, Nasim and  Kreshuk, Anna  and  K\"othe, Ullrich and  Hamprecht, Fred A.},
title={The Mutex Watershed and its Objective: Efficient, Parameter-Free Image Partitioning},
howpublished = {arXiv 1904.12604 [cs.CV]},
year={2019},
}
 @inproceedings{Zheng2015,
 author={Zheng, Shuai and Jayasumana, Sadeep and Romera-Paredes, Bernardino and Vineet, Vibhav and Su, Zhizhong and Du, Dalong and Huang, Chang and Torr, Philip H. S. },
title={Conditional Random Fields as Recurrent Neural Networks},
booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
year={2015}, 
pages={1529-1537},
}

 @ARTICLE{Arbelaez2011,
  author={Arbel\'aez, Pablo and Maire, Michael and Fowlkes, Charles and Malik, Jitendra},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Contour Detection and Hierarchical Image Segmentation}, 
  year={2011},
  month={May},
  volume={33},
  number={5},
  pages={898-916},}
  
@inproceedings{ciresan2012deep,
  title={Deep neural networks segment neuronal membranes in electron microscopy images},
  author={Dan Ciresan and Alessandro Giusti and Luca M. Gambardella and Juergen Schmidhuber},
  booktitle={Proceedings of Neural Information Processing Systems},
  pages={2852--2860},
  year={2012}
}





@INPROCEEDINGS{Dollar2013,
  author={P. {Doll\'ar} and C. L. {Zitnick}},
  booktitle={2013 IEEE International Conference on Computer Vision}, 
  title={Structured Forests for Fast Edge Detection}, 
  year={2013},
  volume={},
  number={},
  pages={1841-1848},}



@Article{Couprie2011,
  author="Couprie, Camille and Grady and Leo and Najman, Laurent and Talbot, Hugues",
  journal="IEEE Transactions on Pattern Analysis and Machine Intelligence", 
  title="Power Watershed: A Unifying Graph-Based Optimization Framework", 
  year="2011",
  volume="33",
  number="7",
  pages="1384-1399",}

@ARTICLE{Turaga19,
  author={J. {Funke} and F. {Tschopp} and W. {Grisaitis} and A. {Sheridan} and C. {Singh} and S. {Saalfeld} and S. C. {Turaga}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title={Large Scale Image Segmentation with Structured Loss Based Deep Learning for Connectome Reconstruction},
  year={2019},
  volume={41},
  number={7},
  pages={1669-1680},
  ISSN={1939-3539},
  month={July},}

@Article{Bansal2004,
author="Bansal, Nikhil
and Blum, Avrim
and Chawla, Shuchi",
title="Correlation Clustering",
journal="Machine Learning",
year="2004",
month="Jul",
day="01",
volume="56",
number="1",
pages="89--113",
abstract="We consider the following clustering problem: we have a complete graph on n vertices (items), where each edge (u, v) is labeled either + or − depending on whether u and v have been deemed to be similar or different. The goal is to produce a partition of the vertices (a clustering) that agrees as much as possible with the edge labels. That is, we want a clustering that maximizes the number of + edges within clusters, plus the number of − edges between clusters (equivalently, minimizes the number of disagreements: the number of − edges inside clusters plus the number of + edges between clusters). This formulation is motivated from a document clustering problem in which one has a pairwise similarity function f learned from past data, and the goal is to partition the current set of documents in a way that correlates with f as much as possible; it can also be viewed as a kind of ``agnostic learning'' problem.",
issn="1573-0565",
doi="10.1023/B:MACH.0000033116.57574.95",
url="https://doi.org/10.1023/B:MACH.0000033116.57574.95"
}

@INPROCEEDINGS{schmidt2009, 
author={F. R. {Schmidt} and E. {Toppe} and D. {Cremers}}, 
booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
title={Efficient planar graph cuts with applications in Computer Vision}, 
year={2009}, 
volume={}, 
number={}, 
pages={351-356}, 
keywords={computer vision;graph theory;image matching;image segmentation;planar graph cuts;computer vision;shape matching;image segmentation;Application software;Computer vision;Shape;Image segmentation;Runtime;Upper bound;Image reconstruction;Stereo image processing;Stereo vision;Dynamic programming}, 
doi={10.1109/CVPR.2009.5206863}, 
ISSN={1063-6919}, 
}

@article{Cousty2009,
  title={Watershed Cuts: Minimum Spanning Forests and the Drop of Water Principle},
  author={Jean Cousty and Gilles Bertrand and Laurent Najman and Michel Couprie},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2009},
  volume={31},
  pages={1362-1374}
}

@inproceedings{Nguyen2019,
author={Nguyen, Quan  and  Porter, Reid and  Zimmer, Beate},
title="Trade-offs between inference and learning in image segmentation",
booktitle={SPIE Proceedings, Applications of Machine Learning},
volume="11139",
editor={Zelinski, Michael E. and  Taha, Tarek M. and  Howe, Jonathan and   Awwal, Abdul A. S. and   Iftekharuddin, Khan M.},
year={2019},
month={September},
}

@inproceedings{Meyer2015,
  title={The waterfall hierarchy on weighted graphs},
  author={Meyer, Fernand },
  booktitle={Mathematical Morphology and Its Applications to Signal and Image Processing. ISSM 2015},
  editor={ Benediktsson J. and Chanussot J. and  Najman L. and Talbot H.},
  series={Lecture Notes in Computer Science},
  publisher={Springer, Cham},
  volume={9082},
  year={2015},
}

@article{Rand,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2284239},
 abstract = {Many intuitively appealing methods have been suggested for clustering data, however, interpretation of their results has been hindered by the lack of objective criteria. This article proposes several criteria which isolate specific aspects of the performance of a method, such as its retrieval of inherent structure, its sensitivity to resampling and the stability of its results in the light of new data. These criteria depend on a measure of similarity between two different clusterings of the same set of data; the measure essentially considers how each pair of data points is assigned in each clustering.},
 author = {William M. Rand},
 journal = {Journal of the American Statistical Association},
 number = {336},
 pages = {846--850},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Objective Criteria for the Evaluation of Clustering Methods},
 volume = {66},
 year = {1971}
}

@inproceedings{Turaga09,
 author = {Turaga, Srinivas C. and Briggman, Kevin L. and Helmstaedter, Moritz and Denk, Winfried and Seung, H. Sebastian},
 title = {Maximin Affinity Learning of Image Segmentation},
 booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems},
 series = {NIPS'09},
 year = {2009},
 isbn = {978-1-61567-911-9},
 location = {Vancouver, British Columbia, Canada},
 pages = {1865--1873},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2984093.2984302},
 acmid = {2984302},
 publisher = {Curran Associates Inc.},
 address = {USA},
}
 
@article{Turaga10,
author = {Turaga, Srinivas C. and Murray, Joseph F. and Jain, Viren and Roth, Fabian and Helmstaedter, Moritz and Briggman, Kevin and Denk, Winfried and Seung, H. Sebastian},
title = {Convolutional Networks Can Learn to Generate Affinity Graphs for Image Segmentation},
journal = {Neural Computation},
volume = {22},
number = {2},
pages = {511-538},
year = {2010},
doi = {10.1162/neco.2009.10-08-881},
    note ={PMID: 19922289},

URL = { https://doi.org/10.1162/neco.2009.10-08-881},
eprint = {
        https://doi.org/10.1162/neco.2009.10-08-881},
    abstract = { Many image segmentation algorithms first generate an affinity graph and then partition it. We present a machine learning approach to computing an affinity graph using a convolutional network (CN) trained using ground truth provided by human experts. The CN affinity graph can be paired with any standard partitioning algorithm and improves segmentation accuracy significantly compared to standard hand-designed affinity functions. We apply our algorithm to the challenging 3D segmentation problem of reconstructing neuronal processes from volumetric electron microscopy (EM) and show that we are able to learn a good affinity graph directly from the raw EM images. Further, we show that our affinity graph improves the segmentation accuracy of both simple and sophisticated graph partitioning algorithms. In contrast to previous work, we do not rely on prior knowledge in the form of hand-designed image features or image preprocessing. Thus, we expect our algorithm to generalize effectively to arbitrary image types. }
}

 @article{Kruskal,
 author={Joseph B. Kruskal},
title={On the shortest spanning subtree of a graph and the traveling salesman problem},
journal={ Proc. Amer. Math. Soc.},
volume=7,
pages={48-50},
year={1956}, 
 }

@InProceedings{PorterOyenZimmer15,
author="Porter, Reid
and Oyen, Diane
and Zimmer, Beate G.",
editor="Benediktsson, J{\'o}n Atli
and Chanussot, Jocelyn
and Najman, Laurent
and Talbot, Hugues",
title="Learning Watershed Cuts Energy Functions",
booktitle="Mathematical Morphology and Its Applications to Signal and Image Processing",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="497--508",
abstract="In recent work, several popular segmentation methods have been unified as energy minimization on a graph. In other work, supervised learning methods have been generalized from predicting labels to predicting structured, graph-like objects. A recent contribution to this second area showed how the Rand Index could be directly minimized when using Connected Components as a segmentation method. We build on this work and present an efficient mini-batch learning method for Connected Component segmentation and also show how it can be generalized to the Watershed Cuts segmentation method. We present initial results applying these new contributions to image segmentation problems in materials microscopy and discuss challenges and future directions.",
isbn="978-3-319-18720-4"
}

@InProceedings{Najman2013,
author="Najman, Laurent
and Cousty, Jean
and Perret, Benjamin",
editor="Hendriks, Cris L. Luengo
and Borgefors, Gunilla
and Strand, Robin",
title="Playing with Kruskal: Algorithms for Morphological Trees in Edge-Weighted Graphs",
booktitle="Mathematical Morphology and Its Applications to Signal and Image Processing",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="135--146",
abstract="The goal of this paper is to provide linear or quasi-linear algorithms for producing some of the various trees used in mathemetical morphology, in particular the trees corresponding to hierarchies of watershed cuts and hierarchies of constrained connectivity. A specific binary tree, corresponding to an ordered version of the edges of the minimum spanning tree, is the key structure in this study, and is computed thanks to variations around Kruskal algorithm for minimum spanning tree.",
isbn="978-3-642-38294-9"
}

@article{kasthuri2015,
title={Saturated reconstruction of a volume of neocortex},
author={Kasthuri, Narayanan and Hayworth, Kenneth Jeffrey and Berger, Daniel Raimund and Schalek, Richard Lee and Conchello, Jos{\'e} Angel and Knowles-Barley, Seymour and Lee, Dongil and V{\'a}zquez-Reina, Amelio and Kaynig, Verena and Jones, Thouis Raymond and others},
journal={Cell},
volume={162},
number={3},
pages={648--661},
year={2015},
publisher={Elsevier},
month={June},
}
  %%%%%%%%%%%%%%%%%%%%above are things we cited so far. Anything below useful?









@inproceedings{Lafferty2001, 
author="Lafferty, John  and McCallum, Andrew  and Pereira, Fernando C.N.",
title="Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data",
booktitle = {ICML ’01: Proceedings of the Eighteenth International Conference on Machine Learning},
year = {2001},
isbn = {1558607781},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
pages={282–289},
}


@inproceedings{Bansal02,
 author = {Bansal, Nikhil and Blum, Avrim and Chawla, Shuchi},
 title = {Correlation Clustering},
 booktitle = {Proceedings of the 43rd Symposium on Foundations of Computer Science},
 series = {FOCS '02},
 year = {2002},
 isbn = {0-7695-1822-2},
 pages = {238},
 url = {http://dl.acm.org/citation.cfm?id=645413.652189},
 acmid = {652189},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 

@Article{Bansal04,
author="Bansal, Nikhil
and Blum, Avrim
and Chawla, Shuchi",
title="Correlation Clustering",
journal="Machine Learning",
year="2004",
month="Jul",
day="01",
volume="56",
number="1",
pages="89--113",
abstract="We consider the following clustering problem: we have a complete graph on n vertices (items), where each edge (u, v) is labeled either + or − depending on whether u and v have been deemed to be similar or different. The goal is to produce a partition of the vertices (a clustering) that agrees as much as possible with the edge labels. That is, we want a clustering that maximizes the number of + edges within clusters, plus the number of − edges between clusters (equivalently, minimizes the number of disagreements: the number of − edges inside clusters plus the number of + edges between clusters). This formulation is motivated from a document clustering problem in which one has a pairwise similarity function f learned from past data, and the goal is to partition the current set of documents in a way that correlates with f as much as possible; it can also be viewed as a kind of ``agnostic learning'' problem.",
issn="1573-0565",
doi="10.1023/B:MACH.0000033116.57574.95",
url="https://doi.org/10.1023/B:MACH.0000033116.57574.95"
}

@ARTICLE{5639015, 
author={Camille Couprie and Leo Grady and Laurent Najman and Hugues Talbot}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Power Watershed: A Unifying Graph-Based Optimization Framework}, 
year={2011}, 
volume={33}, 
number={7}, 
pages={1384-1399}, 
keywords={graph theory;image segmentation;optimisation;power watershed algorithm;unifying graph;graph-based image segmentation;graph cuts algorithm;random walker algorithm;shortest path optimization algorithms;weighted graph;energy function;optimal spanning forest algorithm;energy minimization framework;watershed segmentation;Image segmentation;Image edge detection;Minimization;Pixel;Book reviews;Optimization;Lattices;Combinatorial optimization;image segmentation;graph cuts;random walker;shortest paths;optimal spanning forests;Markov random fields.}, 
doi={10.1109/TPAMI.2010.200}, 
ISSN={0162-8828}, 
month={July},}

@article{Felzenszwalb2004,
title={Efficient Graph-Based Image Segmentation},
author={Pedro F. Felzenszwalb, and Daniel P. Huttenlocher},
journal={International Journal of Computer Vision},
volume={59},
number={2}, 
month={September},
year={2004} ,
}

@BOOK{Sutton2007, 
author={C. {Sutton} and A. {McCallum}}, 
booktitle={An Introduction to Conditional Random Fields}, 
title={An Introduction to Conditional Random Fields}, 
year={2012}, 
volume={}, 
number={}, 
pages={}, 
keywords={Artificial Intelligence;Machine Learning;Computer Science}, 
doi={}, 
ISSN={}, 
publisher={Now Foundations and Trends}, 
isbn={9781601985729}, 
url={https://ieeexplore.ieee.org/document/8186901},}

 





@INPROCEEDINGS{Corso2008, 
author={J. J. {Corso} and A. {Yuille} and {Zhuowen Tu}}, 
booktitle={2008 IEEE Conference on Computer Vision and Pattern Recognition}, 
title={Graph-shifts: Natural image labeling by dynamic hierarchical computing}, 
year={2008}, 
volume={}, 
number={}, 
pages={1-8}, 
keywords={graph theory;image processing;graph-shifts;natural image labeling;dynamic hierarchical computing;energy minimization algorithm;image decomposition;Labeling;Minimization methods;Biomedical imaging;Image segmentation;Tree graphs;Belief propagation;Computer science;Power engineering and energy;Statistics;Nervous system}, 
doi={10.1109/CVPR.2008.4587490}, 
ISSN={1063-6919}, 
month={June},}





@InProceedings{U-net15,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@ARTICLE{watershed,
author={L. Vincent and P. Soille},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Watersheds in digital spaces: an efficient algorithm based on immersion simulations},
year={1991},
volume={13},
number={6},
pages={583-598},
keywords={computerised picture processing;magnetic resonance imagery;computerised picture processing;watersheds;digital gray-scale images;pseudo C language;picture segmentation;digital elevation models;Morphology;Oceans;Computational modeling;Gray-scale;Image segmentation;Digital elevation models;Surfaces;Image processing;Floods;Digital images},
doi={10.1109/34.87344},
ISSN={0162-8828},
month={June},}

@article{connectedcomponents,
 author = {Hopcroft, John and Tarjan, Robert},
 title = {Algorithm 447: Efficient Algorithms for Graph Manipulation},
 journal = {Commun. ACM},
 issue_date = {June 1973},
 volume = {16},
 number = {6},
 month = jun,
 year = {1973},
 issn = {0001-0782},
 pages = {372--378},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/362248.362272},
 doi = {10.1145/362248.362272},
 acmid = {362272},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {analysis of algorithms, graph manipulation, graphs},
}

@InProceedings{Bottou,
author={L\'eon Bottou},
title={Large-Scale Machine Learning with Stochastic Gradient Descent},
booktitle={Proceedings of COMPSTAT’2010},
year={2010},
editor={Y. Lechevallier and G. Saporta},
publisher={Springer-Verlag Berlin Heidelberg },
doi={ 10.1007/978-3-7908-2604-3 16}
}

@inbook{LeCun,
title = "Efficient backprop",
abstract = "The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work. Many authors have suggested that second-order optimization methods are advantageous for neural net training. It is shown that most {"}classical{"} second-order methods are impractical for large neural networks. A few methods are proposed that do not have these limitations.",
author = "LeCun, {Yann A.} and L{\'e}on Bottou and Orr, {Genevieve B.} and M{\"u}ller, {Klaus Robert}",
year = "2012",
doi = "10.1007/978-3-642-35289-8-3",
language = "English (US)",
isbn = "9783642352881",
volume = "7700 LECTURE NO",
series = "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
pages = "9--48",
booktitle = "Neural Networks: Tricks of the Trade",
}


@inproceedings{macqueen1967,
address = "Berkeley, Calif.",
author = "MacQueen, J.",
booktitle = "Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics",
pages = "281--297",
publisher = "University of California Press",
title = "Some methods for classification and analysis of multivariate observations",
url = "https://projecteuclid.org/euclid.bsmsp/1200512992",
year = "1967"
}


@article{Pandove18,
author = {Pandove, Divya and Goel, Shivani and Rani, Rinkle},
title = {Correlation clustering methodologies and their fundamental results},
journal = {Expert Systems},
volume = {35},
number = {1},
pages = {e12229},
keywords = {approximation algorithm, correlation clustering, linear programming, maximizing agreements, minimizing disagreements},
doi = {10.1111/exsy.12229},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.12229},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/exsy.12229},
note = {e12229 10.1111/exsy.12229},
abstract = {Abstract Correlation clustering possibly represents the most intuitive form of clustering construction. It gives solutions that can be approximated while automatically selecting the number of clusters. This approach handles scenarios where the focus is on relationships between the objects instead of on actual representations of the objects. The suitability of this method extends to the structured objects, for which feature vectors are not easy to obtain. Given the increasing scale of data these days, correlation clustering has become a powerful addition to the fields of data mining and agnostic learning. Correlation clustering considers a weighted graph G=(V,E), where the edge weight indicates whether two nodes are similar (positive edge weight) or different (negative edge weight). The task is to find a clustering that either maximizes agreements or minimizes disagreements. Unlike other clustering algorithms, this does not require choosing the number of clusters (k) in advance. The objective to minimize the sum of weights of the cut edges is independent of the number of clusters. Methodologies, such as approximations and linear programming formulations, have been used to approach this problem. This paper focuses on the problem of correlation clustering and lists the solutions proposed by various researchers. These solutions approach the problem using different computational techniques. Correlation clustering-based applications such as entity de-duplication, signed social networks, and problem of aggregating multiples have also been discussed.}
}

@article{rosenblatt1958perceptron,
  title={The perceptron: a probabilistic model for information storage and organization in the brain.},
  author={Rosenblatt, Frank},
  journal={Psychological review},
  volume={65},
  number={6},
  pages={386},
  year={1958},
  publisher={American Psychological Association}
}


@misc{nielsenneural,
  added-at = {2018-02-02T15:47:03.000+0100},
  author = {Nielsen, Michael A.},
  biburl = {https://www.bibsonomy.org/bibtex/274383acee84241145ff4ffede9658206/martin29},
  interhash = {04d527cadd39f888fc3babcad3343362},
  intrahash = {74383acee84241145ff4ffede9658206},
  keywords = {Neural and book deep learning networks},
  publisher = {Determination Press},
  timestamp = {2018-02-02T15:47:03.000+0100},
  title = {Neural Networks and Deep Learning},
  type = {misc},
  url = {http://neuralnetworksanddeeplearning.com/},
  year = 2018
}

@inproceedings{han1995influence,
  title={The influence of the sigmoid function parameters on the speed of backpropagation learning},
  author={Han, Jun and Moraga, Claudio},
  booktitle={International Workshop on Artificial Neural Networks},
  pages={195--201},
  year={1995},
  organization={Springer}
}

@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@inproceedings{zhou1988computation,
  title={Computation of optical flow using a neural network},
  author={Zhou, Yi-Tong and Chellappa, Rama},
  booktitle={IEEE International Conference on Neural Networks},
  volume={1998},
  pages={71--78},
  year={1988}
}

@article{dumoulin2016guide,
  title={A guide to convolution arithmetic for deep learning},
  author={Dumoulin, Vincent and Visin, Francesco},
  journal={arXiv preprint arXiv:1603.07285},
  year={2016}
}

@article{shi2000normalized,
  title={Normalized cuts and image segmentation},
  author={Shi, Jianbo and Malik, Jitendra},
  journal={Departmental Papers (CIS)},
  pages={107},
  year={2000}
}

@article{grady2006random,
  title={Random walks for image segmentation},
  author={Grady, Leo},
  journal={IEEE Transactions on Pattern Analysis \& Machine Intelligence},
  number={11},
  pages={1768--1783},
  year={2006},
  publisher={IEEE}
}

@article{numpy,
  title={The NumPy array: a structure for efficient numerical computation},
  author={Van Der Walt, Stefan and Colbert, S Chris and Varoquaux, Gael},
  journal={Computing in Science \& Engineering},
  volume={13},
  number={2},
  pages={22},
  year={2011},
  publisher={IEEE Computer Society}
}

@article{syntheticdataset,
  title={Color image segmentation based on JND color histogram},
  author={Bhoyar, Kishore and Kakde, Omprakash},
  journal={International Journal of Image Processing (IJIP)},
  volume={3},
  number={6},
  pages={283}
}

@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3431--3440},
  year={2015}
}

@inproceedings{milletari2016v,
  title={V-net: Fully convolutional neural networks for volumetric medical image segmentation},
  author={Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
  booktitle={2016 Fourth International Conference on 3D Vision (3DV)},
  pages={565--571},
  year={2016},
  organization={IEEE}
}

@article{pereira2016brain,
  title={Brain tumor segmentation using convolutional neural networks in {MRI} images},
  author={Pereira, S{\'e}rgio and Pinto, Adriano and Alves, Victor and Silva, Carlos A.},
  journal={IEEE transactions on medical imaging},
  volume={35},
  number={5},
  pages={1240--1251},
  year={2016},
  publisher={IEEE}
}






@incollection{Gull89a, 
	author = "S. F. Gull", 
	title  = "Developments in maximum-entropy data analysis", 
	booktitle= " Maximum Entropy and Bayesian Methods", 
	editor = "J. Skilling", 
	pages  = "53-71 ", 
	publisher= "Kluwer Academic",
	address= "Dordrecht", 
	year   = "1989"	} 
 
@inproceedings{Hanson93c, 
	author = "K. M. Hanson", 
	title  = "Introduction to {B}ayesian image analysis", 
	booktitle= "Medical Imaging:\ Image Processing",
	editor = "M.\ H. Loew",
	series = "Proc. SPIE", 
	volume = "1898",
	pages  = "716-731", 
	year   = "1993"	} 








